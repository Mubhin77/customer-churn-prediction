{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ae79e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 21)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('../data/churn.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51f6fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2416f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape after cleaning: (7032, 21)\n"
     ]
    }
   ],
   "source": [
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df = df.dropna(subset=['TotalCharges'])\n",
    "print(f\"\\nDataset shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a831cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical features: ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
      "Numerical features: ['tenure', 'MonthlyCharges', 'TotalCharges', 'SeniorCitizen']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = [col for col in df.columns \n",
    "                       if df[col].dtype == 'object' and col != 'customerID' and col != 'Churn']\n",
    "numerical_features = [col for col in df.columns \n",
    "                     if df[col].dtype in ['int64', 'float64'] and col not in ['customerID', 'SeniorCitizen']]\n",
    "numerical_features.append('SeniorCitizen')  # Include SeniorCitizen\n",
    "\n",
    "print(\"\\nCategorical features:\", categorical_features)\n",
    "print(\"Numerical features:\", numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f1319af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[categorical_features + numerical_features]\n",
    "y = df['Churn'].map({'Yes': 1, 'No': 0})  # Numeric labels for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aff58fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target distribution:\n",
      "Churn\n",
      "No     5163\n",
      "Yes    1869\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['Churn'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f940b3b9",
   "metadata": {},
   "source": [
    "# 4. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f47c3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set size: 5625\n",
      "Test set size: 1407\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nTrain set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65617772",
   "metadata": {},
   "source": [
    "# 5. Create preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1593555",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd305f",
   "metadata": {},
   "source": [
    "#function to calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2062553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, X_test, y_test, model_name):\n",
    "    \"\"\"Calculate accuracy, precision, recall, F1, and AUC for a model\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"  AUC:       {auc:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7361734",
   "metadata": {},
   "source": [
    "#Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4a077a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RANDOM FOREST CLASSIFIER\n",
      "\n",
      "Random Forest Metrics:\n",
      "  Accuracy:  0.7832\n",
      "  Precision: 0.6228\n",
      "  Recall:    0.4679\n",
      "  F1-Score:  0.5344\n",
      "  AUC:       0.8173\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRANDOM FOREST CLASSIFIER\")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "rf_metrics = calculate_metrics(pipeline, X_test, y_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb7b3e",
   "metadata": {},
   "source": [
    "#logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "117c14df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LOGISTIC REGRESSION\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "  Accuracy:  0.7257\n",
      "  Precision: 0.4901\n",
      "  Recall:    0.7968\n",
      "  F1-Score:  0.6069\n",
      "  AUC:       0.8351\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nLOGISTIC REGRESSION\")\n",
    "\n",
    "log_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "log_model.fit(X_train, y_train)\n",
    "log_metrics = calculate_metrics(log_model, X_test, y_test, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5d61a",
   "metadata": {},
   "source": [
    "#XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32485b4",
   "metadata": {},
   "source": [
    "#Saving the models pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c6003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Models saved:\n",
      "  - churn_model_rf.pkl\n",
      "  - churn_model_lr.pkl\n",
      "  - churn_model_xgb.pkl\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'churn_model_rf.pkl')\n",
    "joblib.dump(log_model, 'churn_model_lr.pkl')\n",
    "\n",
    "print(\"\\n\\nModels saved:\")\n",
    "print(\"  - churn_model_rf.pkl\")\n",
    "print(\"  - churn_model_lr.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a3544",
   "metadata": {},
   "source": [
    "#MODEL COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e5e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "              Model  Accuracy  Precision  Recall  F1-Score    AUC\n",
      "      Random Forest    0.7832     0.6228  0.4679    0.5344 0.8173\n",
      "Logistic Regression    0.7257     0.4901  0.7968    0.6069 0.8351\n",
      "            XGBoost    0.7434     0.5132  0.6738    0.5827 0.8103\n",
      "\n",
      "\n",
      "Model comparison saved as 'model_comparison.csv'\n"
     ]
    }
   ],
   "source": [
    "models_comparison = pd.DataFrame([rf_metrics, log_metrics])\n",
    "models_comparison = models_comparison.round(4)\n",
    "models_comparison.to_csv('model_comparison.csv', index=False)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(models_comparison.to_string(index=False))\n",
    "print(\"\\n\\nModel comparison saved as 'model_comparison.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab47a2",
   "metadata": {},
   "source": [
    "#DETAILED EVALUATION - BEST MODEL (LOGISTIC REGRESSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78aef990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETAILED EVALUATION - LOGISTIC REGRESSION (BEST MODEL)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[723 310]\n",
      " [ 76 298]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.90      0.70      0.79      1033\n",
      "       Churn       0.49      0.80      0.61       374\n",
      "\n",
      "    accuracy                           0.73      1407\n",
      "   macro avg       0.70      0.75      0.70      1407\n",
      "weighted avg       0.79      0.73      0.74      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DETAILED EVALUATION - LOGISTIC REGRESSION (BEST MODEL)\")\n",
    "\n",
    "\n",
    "y_pred = log_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44eed81",
   "metadata": {},
   "source": [
    "#THRESHOLD TUNING ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8b14d218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRESHOLD TUNING ANALYSIS\n",
      "\n",
      "Metrics at different prediction thresholds:\n",
      "(Lower threshold = Higher Recall, Lower Precision)\n",
      "\n",
      "Threshold 0.3:\n",
      "  Accuracy:  0.6326 | Precision: 0.4148 | Recall: 0.9305 | F1: 0.5738\n",
      "Threshold 0.4:\n",
      "  Accuracy:  0.6851 | Precision: 0.4521 | Recall: 0.8717 | F1: 0.5954\n",
      "Threshold 0.5:\n",
      "  Accuracy:  0.7257 | Precision: 0.4901 | Recall: 0.7968 | F1: 0.6069\n",
      "Threshold 0.6:\n",
      "  Accuracy:  0.7633 | Precision: 0.5414 | Recall: 0.7166 | F1: 0.6168\n",
      "Threshold 0.7:\n",
      "  Accuracy:  0.7939 | Precision: 0.6111 | Recall: 0.6176 | F1: 0.6144\n",
      "\n",
      "Threshold analysis saved as 'threshold_analysis.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"THRESHOLD TUNING ANALYSIS\")\n",
    "\n",
    "\n",
    "y_pred_proba = log_model.predict_proba(X_test)[:, 1]\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "threshold_results = []\n",
    "\n",
    "print(\"\\nMetrics at different prediction thresholds:\")\n",
    "print(\"(Lower threshold = Higher Recall, Lower Precision)\\n\")\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred_threshold)\n",
    "    prec = precision_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    auc_val = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc_val\n",
    "    })\n",
    "    \n",
    "    print(f\"Threshold {threshold}:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "threshold_df.to_csv('threshold_analysis.csv', index=False)\n",
    "print(f\"\\nThreshold analysis saved as 'threshold_analysis.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3645ab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMAL THRESHOLD RECOMMENDATION\n",
      "\n",
      "Recommended Threshold: 0.4\n",
      "Rationale: Balances recall (catch churners) with precision (minimize false alarms)\n",
      "\n",
      "Metrics at threshold 0.4:\n",
      "  Accuracy:  0.6851\n",
      "  Precision: 0.4521\n",
      "  Recall:    0.8717\n",
      "  F1-Score:  0.5954\n"
     ]
    }
   ],
   "source": [
    "print(\"OPTIMAL THRESHOLD RECOMMENDATION\")\n",
    "\n",
    "\n",
    "optimal_threshold = 0.4\n",
    "print(f\"\\nRecommended Threshold: {optimal_threshold}\")\n",
    "print(f\"Rationale: Balances recall (catch churners) with precision (minimize false alarms)\")\n",
    "\n",
    "optimal_idx = np.argmin(np.abs(threshold_df['Threshold'] - optimal_threshold))\n",
    "optimal_metrics = threshold_df.iloc[optimal_idx]\n",
    "\n",
    "print(f\"\\nMetrics at threshold {optimal_threshold}:\")\n",
    "print(f\"  Accuracy:  {optimal_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  Precision: {optimal_metrics['Precision']:.4f}\")\n",
    "print(f\"  Recall:    {optimal_metrics['Recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {optimal_metrics['F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d09b17fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYING MODEL WITH OPTIMAL THRESHOLD\n",
      "\n",
      "Deployed model saved as 'churn_model_deployed.pkl'\n",
      "Deployment threshold: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"DEPLOYING MODEL WITH OPTIMAL THRESHOLD\")\n",
    "\n",
    "\n",
    "def predict_churn_with_threshold(model, X_input, threshold=0.4):\n",
    "    \"\"\"Predict churn with custom threshold and risk levels\"\"\"\n",
    "    proba = model.predict_proba(X_input)[:, 1]\n",
    "    prediction = (proba >= threshold).astype(int)\n",
    "    \n",
    "    risk_level = []\n",
    "    for prob in proba:\n",
    "        if prob >= 0.7:\n",
    "            risk_level.append('High Risk')\n",
    "        elif prob >= threshold:\n",
    "            risk_level.append('Medium Risk')\n",
    "        else:\n",
    "            risk_level.append('Low Risk')\n",
    "    \n",
    "    return prediction, proba, risk_level\n",
    "\n",
    "deployment_info = {\n",
    "    'model': log_model,\n",
    "    'threshold': optimal_threshold,\n",
    "    'metrics': optimal_metrics.to_dict()\n",
    "}\n",
    "joblib.dump(deployment_info, 'churn_model_deployed.pkl')\n",
    "print(f\"\\nDeployed model saved as 'churn_model_deployed.pkl'\")\n",
    "print(f\"Deployment threshold: {optimal_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd042ef",
   "metadata": {},
   "source": [
    "#TEST DEPLOYMENT ON SAMPLE CUSTOMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8cb6cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYMENT TEST - SAMPLE CUSTOMER\n",
      "\n",
      "Customer Profile:\n",
      "  Tenure: 12 months\n",
      "  Internet Service: Fiber optic\n",
      "  Contract: Month-to-month\n",
      "  Monthly Charges: $85.50\n",
      "\n",
      "Prediction Results:\n",
      "  Churn Probability: 0.8819 (88.19%)\n",
      "  Risk Level: High Risk\n",
      "  Recommended Action: CONTACT IMMEDIATELY\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_customer = pd.DataFrame([{\n",
    "    'gender': 'Male',\n",
    "    'SeniorCitizen': 0,\n",
    "    'Partner': 'No',\n",
    "    'Dependents': 'No',\n",
    "    'tenure': 12,\n",
    "    'PhoneService': 'Yes',\n",
    "    'MultipleLines': 'No',\n",
    "    'InternetService': 'Fiber optic',\n",
    "    'OnlineSecurity': 'No',\n",
    "    'OnlineBackup': 'No',\n",
    "    'DeviceProtection': 'No',\n",
    "    'TechSupport': 'No',\n",
    "    'StreamingTV': 'Yes',\n",
    "    'StreamingMovies': 'Yes',\n",
    "    'Contract': 'Month-to-month',\n",
    "    'PaperlessBilling': 'Yes',\n",
    "    'PaymentMethod': 'Electronic check',\n",
    "    'MonthlyCharges': 85.50,\n",
    "    'TotalCharges': 1026.00\n",
    "}])\n",
    "\n",
    "sample_prediction, sample_proba, sample_risk = predict_churn_with_threshold(\n",
    "    log_model, sample_customer, threshold=optimal_threshold\n",
    ")\n",
    "\n",
    "print(\"DEPLOYMENT TEST - SAMPLE CUSTOMER\")\n",
    "\n",
    "print(f\"\\nCustomer Profile:\")\n",
    "print(f\"  Tenure: 12 months\")\n",
    "print(f\"  Internet Service: Fiber optic\")\n",
    "print(f\"  Contract: Month-to-month\")\n",
    "print(f\"  Monthly Charges: $85.50\")\n",
    "print(f\"\\nPrediction Results:\")\n",
    "print(f\"  Churn Probability: {sample_proba[0]:.4f} ({sample_proba[0]*100:.2f}%)\")\n",
    "print(f\"  Risk Level: {sample_risk[0]}\")\n",
    "print(f\"  Recommended Action: {'CONTACT IMMEDIATELY' if sample_prediction[0] == 1 else 'Monitor'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aef07ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYMENT TEST - SAMPLE CUSTOMER\n",
      "\n",
      "Customer Profile:\n",
      "  Tenure: 24 months\n",
      "  Internet Service: DSL\n",
      "  Contract: Not Provided\n",
      "  Monthly Charges: $85.50\n",
      "\n",
      "Prediction Results:\n",
      "  Churn Probability: 0.3401 (34.01%)\n",
      "  Risk Level: Low Risk\n",
      "  Recommended Action: Monitor\n"
     ]
    }
   ],
   "source": [
    "sample_customer = pd.DataFrame([{\n",
    "    'gender': 'Male',\n",
    "    'SeniorCitizen': 1,\n",
    "    'Partner': 'Yes',\n",
    "    'Dependents': 'No',\n",
    "    'tenure': 24,\n",
    "    'PhoneService': 'Yes',\n",
    "    'MultipleLines': 'No',\n",
    "    'InternetService': 'DSL',\n",
    "    'OnlineSecurity': 'No',\n",
    "    'OnlineBackup': 'No',\n",
    "    'DeviceProtection': 'No',\n",
    "    'TechSupport': 'Yes',\n",
    "    'StreamingTV': 'Yes',\n",
    "    'StreamingMovies': 'Yes',\n",
    "    'Contract': '',\n",
    "    'PaperlessBilling': 'Yes',\n",
    "    'PaymentMethod': 'Electronic check',\n",
    "    'MonthlyCharges': 85.50,\n",
    "    'TotalCharges': 1026.00\n",
    "}])\n",
    "\n",
    "sample_prediction, sample_proba, sample_risk = predict_churn_with_threshold(\n",
    "    log_model, sample_customer, threshold=optimal_threshold\n",
    ")\n",
    "\n",
    "print(\"DEPLOYMENT TEST - SAMPLE CUSTOMER\")\n",
    "\n",
    "print(f\"\\nCustomer Profile:\")\n",
    "print(f\"  Tenure: {sample_customer.loc[0, 'tenure']} months\")\n",
    "print(f\"  Internet Service: {sample_customer.loc[0, 'InternetService']}\")\n",
    "print(f\"  Contract: {sample_customer.loc[0, 'Contract'] if sample_customer.loc[0, 'Contract'] else 'Not Provided'}\")\n",
    "print(f\"  Monthly Charges: ${sample_customer.loc[0, 'MonthlyCharges']:.2f}\")\n",
    "\n",
    "print(f\"\\nPrediction Results:\")\n",
    "print(f\"  Churn Probability: {sample_proba[0]:.4f} ({sample_proba[0]*100:.2f}%)\")\n",
    "print(f\"  Risk Level: {sample_risk[0]}\")\n",
    "print(f\"  Recommended Action: {'CONTACT IMMEDIATELY' if sample_prediction[0] == 1 else 'Monitor'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "33a0cfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Churn Probability  Predicted Churn Risk Level\n",
      "2499           0.093566                0   Low Risk\n",
      "5830           0.077484                0   Low Risk\n",
      "1774           0.505824                0   Low Risk\n",
      "1328           0.396368                0   Low Risk\n",
      "2673           0.757965                1  High Risk\n"
     ]
    }
   ],
   "source": [
    "new_data = X_test.sample(5)\n",
    "pred, proba, risk = predict_churn_with_threshold(log_model, new_data, threshold=0.6)\n",
    "\n",
    "results = new_data.copy()\n",
    "results['Churn Probability'] = proba\n",
    "results['Predicted Churn'] = pred\n",
    "results['Risk Level'] = risk\n",
    "\n",
    "print(results[['Churn Probability', 'Predicted Churn', 'Risk Level']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20b20948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL DEPLOYMENT DEMO\n",
      "\n",
      "ðŸ”¹ Predicted Churn Risk for Sample Customers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn Probability</th>\n",
       "      <th>Predicted Churn</th>\n",
       "      <th>Risk Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6970</th>\n",
       "      <td>87.6%</td>\n",
       "      <td>1</td>\n",
       "      <td>High Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>8.6%</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658</th>\n",
       "      <td>54.8%</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>6.3%</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.5%</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Churn Probability  Predicted Churn   Risk Level\n",
       "6970             87.6%                1    High Risk\n",
       "6331              8.6%                0     Low Risk\n",
       "4658             54.8%                1  Medium Risk\n",
       "3471              6.3%                0     Low Risk\n",
       "192               0.5%                0     Low Risk"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nMODEL DEPLOYMENT DEMO\")\n",
    "\n",
    "\n",
    "# Sample 5 random customers from test data\n",
    "sample_customers = X_test.sample(5, random_state=42)\n",
    "\n",
    "# Get predictions using the deployment function\n",
    "predictions, probabilities, risk_levels = predict_churn_with_threshold(\n",
    "    log_model, sample_customers, threshold=0.4\n",
    ")\n",
    "\n",
    "# Combine into a DataFrame for readability\n",
    "demo_results = sample_customers.copy()\n",
    "demo_results['Churn Probability'] = probabilities\n",
    "demo_results['Predicted Churn'] = predictions\n",
    "demo_results['Risk Level'] = risk_levels\n",
    "\n",
    "\n",
    "demo_results['Churn Probability'] = demo_results['Churn Probability'].apply(lambda x: f\"{x*100:.1f}%\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ”¹ Predicted Churn Risk for Sample Customers:\")\n",
    "display(demo_results[['Churn Probability', 'Predicted Churn', 'Risk Level']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
